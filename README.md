# bridgestore-lakeflow-declarative
Pipeline Lakehouse no Databricks para o e-commerce Bridgestore, com ingest√£o via Airbyte e organiza√ß√£o Bronze/Silver/Gold.

BridgeStore Lakehouse Project
üìå Vis√£o Geral

Este projeto tem como objetivo criar um pipeline de dados para an√°lise de vendas da BridgeStore, utilizando arquitetura Lakehouse no Databricks.
O fluxo inclui ingest√£o de dados, transforma√ß√£o em camadas Silver, e cria√ß√£o de m√©tricas agregadas em camada Gold para an√°lises de neg√≥cios.


<img width="990" height="281" alt="imagem_etlpng" src="https://github.com/user-attachments/assets/066697b9-f2ed-4ca5-965b-0d3296b4abbc" />

----
Vis√£o Geral

Este projeto implementa um pipeline de dados completo para an√°lise de vendas da BridgeStore, usando arquitetura Lakehouse. O objetivo √© transformar dados transacionais brutos em m√©tricas de neg√≥cios confi√°veis para suporte a decis√µes.

üèóÔ∏è Arquitetura Funcional do Pipeline

O fluxo de dados segue 3 camadas principais e utiliza ferramentas espec√≠ficas para cada etapa:

1. Ingest√£o (Bronze)
    
    Fonte de dados: MySQL transacional (dados de pedidos, clientes, produtos, categorias e lojas)
    
    Ferramenta: Airbyte
    
    Conecta MySQL ao Databricks.
    
    Infer√™ncia autom√°tica de esquema.
    
    Sincroniza√ß√£o incremental ou full refresh.
    
    Objetivo: replicar dados brutos no Data Lake sem altera√ß√µes.

2. Transforma√ß√£o e Limpeza (Silver)

    Ferramenta: Databricks Lakehouse (Delta Lake + Unity Catalog)
    
    Opera√ß√µes:
    
    Valida√ß√£o de integridade (order_id IS NOT NULL, shipped_date >= order_date)
    
    Enriquecimento de dados com joins entre tabelas transacionais.
    
    Cria√ß√£o de tabela clean_sales_data (silver) com informa√ß√µes combinadas de:
    
    Pedidos
    
    Produtos
    
    Clientes
    
    Lojas
    
    Categorias
    
    Benef√≠cio: camada confi√°vel, pronta para an√°lises e agrega√ß√µes Gold.

3. Agrega√ß√£o e M√©tricas (Gold)

    Ferramenta: Databricks Materialized Views
    
    Objetivo: gerar m√©tricas de neg√≥cios diretamente no Lakehouse.
    
    Views criadas:
    
    daily_sales: vendas di√°rias (quantidade, receita, pedidos)
    
    store_performance: desempenho por loja
    
    customer_lifetime_value: valor total gasto por cliente, ticket m√©dio, primeira e √∫ltima compra
    
    product_category_performance: vendas por categoria de produto
    
    Filtro importante: pedidos cancelados ou pendentes s√£o exclu√≠dos da receita.

‚ö° Ferramentas e Tecnologias
Etapa	Ferramenta / Tecnologia	Fun√ß√£o
Ingest√£o	Airbyte	Conectar MySQL ao Data Lake, inferir esquema
Armazenamento	Azure Data Lake (ADLS)	Armazenar arquivos Delta brutos e tratados
Transforma√ß√£o	Databricks + Delta Lake	Limpeza, valida√ß√£o e joins
Cataloga√ß√£o	Unity Catalog	Organiza√ß√£o de databases e tabelas
Agrega√ß√£o	Materialized Views (Databricks)	M√©tricas Gold prontas para an√°lise
üîó Fluxo Resumido do Pipeline

MySQL ‚Üí Airbyte ‚Üí Bronze
Dados transacionais brutos armazenados em Delta Lake.

Bronze ‚Üí Databricks ‚Üí Silver
Limpeza, valida√ß√£o e enriquecimento ‚Üí clean_sales_data.

Silver ‚Üí Gold
Materialized Views com m√©tricas de vendas e performance:

daily_sales

store_performance

customer_lifetime_value

product_category_performance

Consumo de dados
Dashboards em Databricks SQL ou Power BI, relat√≥rios gerenciais e an√°lises de clientes, lojas e produtos.
